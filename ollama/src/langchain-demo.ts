import { ChatOllama } from '@langchain/ollama'
import { HumanMessage, SystemMessage, AIMessage } from '@langchain/core/messages'

// åˆ›å»º Ollama æ¨¡åž‹å®žä¾‹
const llm = new ChatOllama({
  model: 'deepseek-r1',
  baseUrl: 'http://localhost:11434', // Ollama é»˜è®¤åœ°å€
  temperature: 0.7, // æ¸©åº¦å‚æ•°ï¼ŒæŽ§åˆ¶éšæœºæ€§
  maxRetries: 2,
})

async function main() {
  console.log('ðŸš€ å¼€å§‹è°ƒç”¨ deepseek-r1 æ¨¡åž‹...\n')

  // ç¤ºä¾‹ 1: ç®€å•å¯¹è¯
  console.log('--- ç¤ºä¾‹ 1: ç®€å•å¯¹è¯ ---')
  const message = new HumanMessage('ç”¨ä¸€å¥è¯ä»‹ç» TypeScript')
  const response = await llm.invoke([message])
  console.log('å›žç­”:', response.content)
  console.log()

  // ç¤ºä¾‹ 2: æµå¼è¾“å‡º
  console.log('--- ç¤ºä¾‹ 2: æµå¼è¾“å‡º ---')
  const stream = await llm.stream([new HumanMessage('å†™ä¸€ä¸ª Python Hello World ç¤ºä¾‹')])
  process.stdout.write('å›žç­”: ')
  for await (const chunk of stream) {
    process.stdout.write(chunk.content)
  }
  console.log('\n')

  // ç¤ºä¾‹ 3: å¤šè½®å¯¹è¯
  console.log('--- ç¤ºä¾‹ 3: å¤šè½®å¯¹è¯ ---')
  const chatHistory = [
    { role: 'system', content: 'ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„ç¼–ç¨‹åŠ©æ‰‹ã€‚' },
    { role: 'user', content: 'ä»€ä¹ˆæ˜¯ Reactï¼Ÿ' },
    { role: 'assistant', content: 'React æ˜¯ä¸€ä¸ªç”¨äºŽæž„å»ºç”¨æˆ·ç•Œé¢çš„ JavaScript åº“ã€‚' },
    { role: 'user', content: 'å®ƒæœ‰å“ªäº›ä¸»è¦ç‰¹ç‚¹ï¼Ÿ' },
  ]
  const chatResponse = await llm.invoke(chatHistory.map(msg => {
    switch (msg.role) {
      case 'system':
        return new SystemMessage(msg.content)
      case 'assistant':
        return new AIMessage(msg.content)
      case 'user':
        return new HumanMessage(msg.content)
      default:
        return new HumanMessage(msg.content)
    }
  }))
  console.log('å›žç­”:', chatResponse.content)
}

main().catch(console.error)
